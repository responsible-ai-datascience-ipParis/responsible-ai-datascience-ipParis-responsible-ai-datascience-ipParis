<!doctype html><html lang=en><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=author content="Liste - https://responsible-ai-datascience-ipParis.github.io/"><title>Articles | Bloggin on Responsible AI</title>
<meta name=description content="Bloggin on Responsible AI"><meta property="og:title" content="Articles"><meta property="og:description" content="Hereafter you can find the list of articles proposed for this class and the link to the pdfs.
Please add your name in the following file to pick an article and enter your github username.
Note 1: this work can be done in teams (maximum 2 students).
Note 2: an article can only be chosen by 1 team.
Interpretable AI Jayneel Parekh, Pavlo Mozharovskyi, Florence d&rsquo;Alché-Buc, A Framework to Learn with Interpretation."><meta property="og:type" content="article"><meta property="og:url" content="https://responsible-ai-datascience-ipParis.github.io/articles/"><meta property="article:section" content="pages"><meta itemprop=name content="Articles"><meta itemprop=description content="Hereafter you can find the list of articles proposed for this class and the link to the pdfs.
Please add your name in the following file to pick an article and enter your github username.
Note 1: this work can be done in teams (maximum 2 students).
Note 2: an article can only be chosen by 1 team.
Interpretable AI Jayneel Parekh, Pavlo Mozharovskyi, Florence d&rsquo;Alché-Buc, A Framework to Learn with Interpretation."><meta itemprop=wordCount content="485"><meta itemprop=keywords content><link rel=canonical href=https://responsible-ai-datascience-ipParis.github.io/articles/><link rel=icon href=https://responsible-ai-datascience-ipParis.github.io//assets/favicon.ico><link rel=dns-prefetch href=https://www.google-analytics.com><link href=https://www.google-analytics.com rel=preconnect crossorigin><link rel=alternate type=application/atom+xml title="Bloggin on Responsible AI" href=https://responsible-ai-datascience-ipParis.github.io//atom.xml><link rel=alternate type=application/json title="Bloggin on Responsible AI" href=https://responsible-ai-datascience-ipParis.github.io//feed.json><link rel="shortcut icon" type=image/png href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAQAAAC1HAwCAAAAC0lEQVR42mNk+A8AAQUBAScY42YAAAAASUVORK5CYII="><style>*,:after,:before{box-sizing:border-box;padding:0}body{font:1rem/1.5 '-apple-system',BlinkMacSystemFont,avenir next,avenir,helvetica,helvetica neue,ubuntu,roboto,noto,segoe ui,arial,sans-serif;text-rendering:optimizeLegibility;-webkit-font-smoothing:antialiased;-moz-osx-font-smoothing:grayscale;padding:2rem;background:#f5f5f5;color:#000}.skip-link{position:absolute;top:-40px;left:0;background:#eee;z-index:100}.skip-link:focus{top:0}h1,h2,h3,h4,h5,strong,b{font-size:inherit;font-weight:600}header{line-height:2;padding-bottom:1.5rem}.link{overflow:hidden;text-overflow:ellipsis;white-space:nowrap;overflow:hidden;text-overflow:ellipsis;text-decoration:none}.time{font-variant-numeric:tabular-nums;white-space:nowrap}blockquote{border-left:5px solid #eee;padding-left:1rem;margin:0}a,a:visited{color:inherit}a:hover,a.heading-link{text-decoration:none}pre{padding:.5rem;overflow:auto;overflow-x:scroll;overflow-wrap:normal}code,pre{font-family:San Francisco Mono,Monaco,consolas,lucida console,dejavu sans mono,bitstream vera sans mono,monospace;font-size:normal;font-size:small;background:#eee}code{margin:.1rem;border:none}ul{list-style-type:square}ul,ol{padding-left:1.2rem}.list{line-height:2;list-style-type:none;padding-left:0}.list li{padding-bottom:.1rem}.meta{color:#777}.content{max-width:70ch;margin:0 auto}header{line-height:2;display:flex;justify-content:space-between;padding-bottom:1rem}header a{text-decoration:none}header ul{list-style-type:none;padding:0}header li,header a{display:inline}h2.post{padding-top:.5rem}header ul a:first-child{padding-left:1rem}.nav{height:1px;background:#000;content:'';max-width:10%}.list li{display:flex;align-items:baseline}.list li time{flex:initial}.hr-list{margin-top:0;margin-bottom:0;margin-right:.5rem;margin-left:.5rem;height:1px;border:0;border-bottom:1px dotted #ccc;flex:1 0 1rem}.m,hr{border:0;margin:3rem 0}img{max-width:100%;height:auto}.post-date{margin:5% 0}.index-date{color:#9a9a9a}.animate-blink{animation:opacity 1s infinite;opacity:1}@keyframes opacity{0%{opacity:1}50%{opacity:.5}100%{opacity:0}}.tags{display:flex;justify-content:space-between}.tags ul{padding:0;margin:0}.tags li{display:inline}.avatar{height:120px;width:120px;position:relative;margin:-10px 0 0 15px;float:right;border-radius:50%}</style><script type=application/ld+json>{"@context":"http://schema.org","@type":"BlogPosting","articleSection":"pages","name":"Articles","headline":"Articles","alternativeHeadline":"","description":"Hereafter you can find the list of articles proposed for this class and the link to the pdfs.\nPlease add your name in the following file to pick an article and enter your github username.\nNote 1: this work can be done in teams (maximum 2 students).\nNote 2: an article can only be chosen by 1 team.\nInterpretable AI Jayneel Parekh, Pavlo Mozharovskyi, Florence d\u0026rsquo;Alché-Buc, A Framework to Learn with Interpretation.","inLanguage":"en-us","isFamilyFriendly":"true","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/responsible-ai-datascience-ipParis.github.io\/articles\/"},"author":{"@type":"Person","name":""},"creator":{"@type":"Person","name":""},"accountablePerson":{"@type":"Person","name":""},"copyrightHolder":"Bloggin on Responsible AI","copyrightYear":"0001","dateCreated":"0001-01-01T00:00:00.00Z","datePublished":"0001-01-01T00:00:00.00Z","dateModified":"0001-01-01T00:00:00.00Z","publisher":{"@type":"Organization","name":"Bloggin on Responsible AI","url":"https://responsible-ai-datascience-ipParis.github.io/","logo":{"@type":"ImageObject","url":"https:\/\/responsible-ai-datascience-ipParis.github.io\/assets\/favicon.ico","width":"32","height":"32"}},"image":"https://responsible-ai-datascience-ipParis.github.io/assets/favicon.ico","url":"https:\/\/responsible-ai-datascience-ipParis.github.io\/articles\/","wordCount":"485","genre":[],"keywords":[]}</script></head><body><a class=skip-link href=#main>Skip to main</a><main id=main><div class=content><header><p style=padding:0;margin:0><a href=../><b>Bloggin on Responsible AI</b>
<span class="text-stone-500 animate-blink">▮</span></a></p><ul style=padding:0;margin:0><li><a href=../posts/><span>Post</span></a><li><a href=../tutorial/><span>Tutorial</span></a><li><a href=../about/><span>About</span></a><li><a href=../articles/><span>Articles</span></a></li></ul></header><hr class=hr-list style=padding:0;margin:0><section><h2 class=post>Articles</h2><p>Hereafter you can find the list of articles proposed for this class and the link to the pdfs.</p><p>Please add your name in the following <a href="https://docs.google.com/spreadsheets/d/1raZrD6JZQzjE0wmJbP4iM5-4yt9rAkJIFOqgj1q-JxU/edit?usp=sharing">file</a> to pick an article and enter your <strong>github username</strong>.</p><p><strong>Note 1</strong>: this work can be done in teams (<span style=text-decoration:underline>maximum 2 students</span>).</p><p><strong>Note 2</strong>: an article can only be chosen by <span style=text-decoration:underline>1 team</span>.</p><hr><h2 id=interpretable-ai>Interpretable AI</h2><ul><li>Jayneel Parekh, Pavlo Mozharovskyi, Florence d&rsquo;Alché-Buc, A Framework to Learn with Interpretation. Advances in Neural Information Processing Systems (2021)<a href=https://proceedings.neurips.cc/paper/2021/file/cbb6a3b884f4f88b3a8e3d44c636cbd8-Paper.pdf>[link to pdf]</a></li><li>Jonathan Crabbé, Mihaela van der Schaar, Label-Free Explainability for Unsupervised Models, International Conference on Machine Learning (2022) <a href=https://proceedings.mlr.press/v162/crabbe22a.html>[link to pdf]</a></li><li>Hamilton, M., Lundberg, S., Fu, S., Zhang, L., & Freeman, W. T., Axiomatic Explanations for Visual Search, Retrieval, and Similarity Learning. In International Conference on Learning Representations (2021) <a href="https://openreview.net/pdf?id=TqNsv1TuCX9">[link to pdf]</a></li></ul><h2 id=frugal-ai>Frugal AI</h2><ul><li>Wang, Zijian, et al. <em>How Far Pre-trained Models Are from Neural Collapse on the Target Dataset Informs their Transferability.</em> Proceedings of the IEEE/CVF International Conference on Computer Vision. (2023). <a href=https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_How_Far_Pre-trained_Models_Are_from_Neural_Collapse_on_the_ICCV_2023_paper.pdf>[link to pdf]</a>.</li><li>Wang, Yite, Dawei Li, and Ruoyu Sun. <em>NTK-SAP: Improving neural network pruning by aligning training dynamics.</em> International Conference on Learning Representations (2023). <a href=https://arxiv.org/abs/2304.02840>[link to pdf]</a>.</li><li>Bragagnolo, Andrea, Enzo Tartaglione, and Marco Grangetto. <em>To update or not to update? Neurons at equilibrium in deep models.</em> Advances in Neural Information Processing Systems (2022). <a href=https://proceedings.neurips.cc/paper_files/paper/2022/file/8b2fc235787852ead92da2268cd9e90c-Paper-Conference.pdf>[link to pdf]</a>.</li><li>Yang, Adam X and Robeyns, Maxime and Wang, Xi and Aitchison, Laurence, Bayesian low-rank adaptation for large language models, International Conference on Learning Representations (2024) <a href="https://openreview.net/pdf?id=FJiUyzOF1m">[link to pdf]</a></li></ul><h2 id=robust-ai>Robust AI</h2><ul><li>Olivier Laurent, Adrien Lafage, Enzo Tartaglione, Geoffrey Daniel, Jean-Marc Martinez, Andrei Bursuc, Gianni Franchi. <em>Packed-Ensembles for Efficient Uncertainty Estimation</em>, International Conference on Learning Representations (2023). <a href="https://openreview.net/pdf?id=XXTyv1zD9zD">[link to pdf]</a>.</li><li>Francesco Pinto, Harry Yang, Ser-Nam Lim, Philip H.S. Torr, Puneet K. Dokania, <em>RegMixup: Mixup as a Regularizer Can Surprisingly Improve Accuracy and Out Distribution Robustness</em>, Advances in Neural Information Processing Systems (2022).<a href="https://openreview.net/pdf?id=5j6fWcPccO">[link to pdf]</a>.</li><li>Roy Ganz, Bahjat Kawar, Michael Elad, <em>Do Perceptually Aligned Gradients Imply Robustness?</em>, International Conference on Machine Learning (2023). <a href=http://proceedings.mlr.press/v202/ganz23a/ganz23a.pdf>[link to pdf]</a>.</li><li>Anonymous, Optimal Transport Based Adversarial Patch to Leverage Large Scale Attack Transferability, International Conference in Representation Learning, to appear 2024 <a href="https://openreview.net/forum?id=nZP10evtkV">[link to pdf]</a></li></ul><h2 id=fairness>Fairness</h2><ul><li>R. Vogel, A. Bellet and S. Clémençon. <em>Learning Fair Scoring Functions: Bipartite Ranking under ROC-based Fairness Constraints.</em> International Conference on Artificial Intelligence and Statistics (AISTATS), 2021. <a href=http://researchers.lille.inria.fr/abellet/papers/aistats21.pdf>[link to pdf]</a>, <a href=http://researchers.lille.inria.fr/abellet/papers/aistats21_supp.pdf>[link to supplementary]</a>.</li><li>Preethi Lahoti et al. <em>Fairness without Demographics through Adversarially Reweighted Learning</em>. Advances in Neural Information Processing Systems (2020). <a href=https://proceedings.neurips.cc/paper/2020/file/07fc15c9d169ee48573edd749d25945d-Paper.pdf>[link to pdf]</a>, <a href=https://github.com/lucweytingh/ARL-UvA>[link to github]</a>.</li></ul><h2 id=privacy>Privacy</h2><ul><li>John C. Duchi, Michael I. Jordan, and Martin Wainwright. Privacy Aware Learning. Advances in Neural Information Processing Systems (2012). <a href=https://web.stanford.edu/~jduchi/projects/DuchiJoWa12.html>[link to pdf]</a>.</li><li>John C. Duchi, Michael I. Jordan, and Martin Wainwright. Local Privacy and Statistical Minimax Rates. FOCS (2013). <a href=https://arxiv.org/abs/1302.3203>[link to pdf]</a>.</li><li>John C. Duchi, Michael I. Jordan, and Martin Wainwright. Local Privacy and Minimax Bounds: Sharp Rates for Probability Estimation. Advances in Neural Information Processing Systems (2013). <a href=https://proceedings.neurips.cc/paper_files/paper/2013/file/5807a685d1a9ab3b599035bc566ce2b9-Paper.pdf>[link to pdf]</a>.</li></ul></section></div></main></body></html>