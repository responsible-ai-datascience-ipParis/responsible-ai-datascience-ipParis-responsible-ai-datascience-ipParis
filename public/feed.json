{
  "version": "https://jsonfeed.org/version/1",
  "title": "Bloggin on Responsible AI",
  "home_page_url": "http://localhost:1313/",
  "feed_url": "http://localhost:1313/feed.json",
  "description": "Bloggin on Responsible AI",
  "favicon": "http://localhost:1313//assets/favicon.ico",
  "expired": false,
  "author": {
    "name": "Students from M2 Data Science IP Paris",
    "url": "http://localhost:1313/"
  },
  "items": [
    
    

    
    {
      "id": "7caf312b2212cb7ecf9bc99e08261d1c412013a5",
      "title": "Label-Free Explainability",
      "summary": "",
      "content_text": "Label-Free Explainability for Unsupervised Models Authors: Valentina Hu and Selma Zarga Table of Contents Introduction Experiment Why do we need explainability ? Machine learning models are becoming increasingly capable of making advanced predictions. While models like linear regression are relatively easy to understand and explain, more complex models, often called \u0026ldquo;black boxes\u0026rdquo; due to their complexity, present challenges in explaining how they make predictions. These models can be problematic in highstakes applications such as healthcare, finance, and justice, where it\u0026rsquo;s crucial to justify decision-making. Additionally, in case of errors, it\u0026rsquo;s important to understand the origin in order to address and correct them.\n\u0026ldquo;Explainability is the cornerstone of trust in black box models; without it, they remain inscrutable and unreliable.\u0026rdquo; - Yoshua Bengio\nTo tackle this challenge, the field of Explainable Artificial Intelligence (XAI) has emerged, offering various methods to enhance model transparency. Post-Hoc explainability methods exist, which intervene after the model has generated its results, enabling users to comprehend the reasoning behind specific decisions or predictions. These methods supplement the predictions of black box models with diverse explanations of how they arrive at their predictions.\nWhile much of the work on explainability focuses on supervised models, where labels are available to interpret predictions, unsupervised learning models are trained without labels. This post will focus on these unsupervised, label-free cases. It is based on recent research conducted by Crabbé and van der Schaar in 2022, which explores the explainability of unsupervised models. They have developed two new methods to explain these complex models without labels. The first method highlights important features in the data, while the second identifies training examples that have the greatest impact on the model\u0026rsquo;s construction of representations.\nExperiments: Evaluation and Results Overview In this section, we provide an overview of the experiment conducted to evaluate the label-free extensions of various explanation methods for unsupervised models. The experiment is divided into two main parts: consistency checks and comparisons of representations learned from different pretext tasks.\nReferences Crabbé, J. \u0026amp; van der Schaar, M.. (2022). Label-Free Explainability for Unsupervised Models. Proceedings of the 39th International Conference on Machine Learning, in Proceedings of Machine Learning Research 162:4391-4420 Available from https://proceedings.mlr.press/v162/crabbe22a.html. ",
      "content_html": "\u003ch1 style=\"font-size: 36px;\"\u003eLabel-Free Explainability for Unsupervised Models\u003c/h1\u003e\n\u003ch1 style=\"font-size: 18px;\"\u003eAuthors: \u003ca href=\"https://github.com/Valentinahxu\"\u003eValentina Hu \u003c/a\u003e and  \u003ca href=\"https://github.com/selmazrg\"\u003e Selma Zarga\u003c/a\u003e\u003c/h1\u003e\n\u003ch1 id=\"table-of-contents\"\u003eTable of Contents\u003c/h1\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"#section-0\"\u003eIntroduction\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#section-5\"\u003eExperiment\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"section-0\"\u003eWhy do we need explainability ?\u003c/h2\u003e\n\u003cp\u003eMachine learning models are becoming increasingly capable of making advanced predictions. While models like linear regression are relatively easy to understand and explain, more complex models, often called \u003cstrong\u003e\u0026ldquo;black boxes\u0026rdquo;\u003c/strong\u003e due to their complexity, present challenges in explaining how they make predictions. These models can be problematic in highstakes applications such as healthcare, finance, and justice, where it\u0026rsquo;s crucial to justify decision-making. Additionally, in case of errors, it\u0026rsquo;s important to understand the origin in order to address and correct them.\u003c/p\u003e\n\u003ccenter\u003e\n\u003cp\u003e\u0026ldquo;\u003cstrong\u003eExplainability is the cornerstone of trust in black box models; without it, they remain inscrutable and unreliable.\u003c/strong\u003e\u0026rdquo; - \u003cem\u003eYoshua Bengio\u003c/em\u003e\u003c/p\u003e\n\u003c/center\u003e\n\u003cp\u003eTo tackle this challenge, the field of Explainable Artificial Intelligence (XAI) has emerged, offering various methods to enhance \u003cstrong\u003emodel transparency\u003c/strong\u003e. \u003cstrong\u003ePost-Hoc explainability\u003c/strong\u003e methods exist, which intervene after the model has generated its results, enabling users to comprehend the reasoning behind specific decisions or predictions. These methods supplement the predictions of black box models with diverse explanations of how they arrive at their predictions.\u003c/p\u003e\n\u003cp\u003e\u003cimg\n  src=\"/images/explainability/blackboxpng.webp\"\n  alt=\"XAI explainability\"\n  loading=\"lazy\"\n  decoding=\"async\"\n  class=\"full-width\"\n/\u003e\n\n\u003c/p\u003e\n\u003cp\u003eWhile much of the work on explainability focuses on supervised models, where labels are available to interpret predictions, unsupervised learning models are trained without labels. This post will focus on these unsupervised, label-free cases. It is based on recent research conducted by Crabbé and van der Schaar in 2022, which explores the explainability of unsupervised models. They have developed two new methods to explain these complex models without labels. The first method highlights important features in the data, while the second identifies training examples that have the greatest impact on the model\u0026rsquo;s construction of representations.\u003c/p\u003e\n\u003ch2 id=\"section-5\"\u003eExperiments: Evaluation and Results\u003c/h2\u003e\n\u003ch3 id=\"section-111\"\u003eOverview\u003c/h3\u003e\n\u003cp\u003eIn this section, we provide an overview of the experiment conducted to evaluate the label-free extensions of various explanation methods for unsupervised models. The experiment is divided into two main parts: consistency checks and comparisons of representations learned from different pretext tasks.\u003c/p\u003e\n\u003ch3 id=\"references\"\u003eReferences\u003c/h3\u003e\n\u003col\u003e\n\u003cli\u003eCrabbé, J. \u0026amp; van der Schaar, M.. (2022). Label-Free Explainability for Unsupervised Models. \u003ci\u003eProceedings of the 39th International Conference on Machine Learning\u003c/i\u003e, in \u003ci\u003eProceedings of Machine Learning Research\u003c/i\u003e 162:4391-4420 Available from \u003ca href=\"https://proceedings.mlr.press/v162/crabbe22a.html\"\u003ehttps://proceedings.mlr.press/v162/crabbe22a.html\u003c/a\u003e.\u003c/li\u003e\n\u003c/ol\u003e\n",
      "url": "http://localhost:1313/posts/label-free-explainability/",
      "date_published": "17036-17-09T331:1717:00+01:00",
      "date_modified": "17036-17-09T331:1717:00+01:00",
      "author": {
        "name": "Students from M2 Data Science IP Paris",
        "url": "http://localhost:1313/"
      }
    },
    
    {
      "id": "00988a4ecebb51af6cf28a7b318568929bf7a01d",
      "title": "Statistical Minimax Rates Under Privacy",
      "summary": "",
      "content_text": "Estimating Privacy in Data Science: A Comprehensive Guide Author: Antoine Klein Github Link Table of Contents Incentives Introduction Definition Theory The case of multinomial estimation The case of density estimation Experiment Conclusion Quizz Why do we care about privacy ? Imagine, you\u0026rsquo;re quietly at home when the doorbell rings. You open the door and a government official appears: population census. Even though he shows you his official badge and you\u0026rsquo;d like to help him in the public interest, you find it hard to answer his questions as you go along. Indeed, the first questions about the date of your move are easy and public. On the other hand, when he asks about the number of children, marital status or your salary and what you do with it, you struggle. Not because you don\u0026rsquo;t know the answer, but because you\u0026rsquo;re faced with an ethical dilemma: transparency towards the state versus protection of personal data.\n$$\\text{In short, transparency goes against your privacy. }$$\nThis stress has major consequences: as you doubt what could happen to you with this data, but you still want to answer it, you underestimate your answers. On a wider scale, this leads to a suffrage bias and therefore a lack of knowledge of the real situation of your population. Warner [1], the first to tackle this problem from a statistical angle talks of an evasive bias and says:\n\u0026ldquo;for reasons of modesty, fear of being thought bigoted, or merely a reluctance to confide secrets to strangers, respondents to surveys might prefer to be able to answer certain questions non-truthfully, or at least without the interviewer knowing their true response\u0026rdquo;\nThis situation presented a trusted agent, in that he wasn\u0026rsquo;t trying to harm you directly. Now imagine that you agree to give him your personal data, but that on the way home, this agent of the state is mugged and someone steals his documents. Not only is this an attack on his person, it\u0026rsquo;s also an attack on yours: as the guarantor of your data, it\u0026rsquo;s now at the mercy of the attacker. The problem here is not to have protected yourself against a malicious agent.\nAdmittedly, these situations are rare, but with the densification of data, their analogies are omnipresent: cookies on the Internet, cyber-attacks, datacenter crashes\u0026hellip;One area for improvement is quite simply to better certify usage by means of cyber protection labels and leads to such a norm to achieve trust: In this blog, we propose to tackle this problem from a completely different angle: how to both enable the agent to take global measures and prevent it and any subsequent malicious agents from being able to re-identify my personal data. We\u0026rsquo;ll also use minimax bounds to answer the question: for a given privacy criterion, what\u0026rsquo;s the loss in terms of estimation? (fundamental trade-offs between privacy and convergence rate)\nScientific introduction Our blog will follow the same plan as the article that inspired it (John C. Duchi [2]),i.e. to show that response randomization achieves optimal convergence in the case of multinomial estimation, and then that this process can be generalized to any nonparametric distribution estimation. To this end, we will introduce the notion of local differential privacy as well as the minimax theory for obtaining optimal limits. All this will shed light on the trade-off between privacy and estimation rates. We will also explain algorithms to implement these optimal strategies. Finally, we will propose some experimental results.\nSome key definitions Let assume that you want to make private $X_1 , \u0026hellip; , X_n \\in X$ random variable and, as the statistician, you only observe $Z_1, . . . , Z_n ∈ Z$. The paper assumes that there exist a markov kernel that links the true ramdom variables and the observed ones as follow: $Q_i(Z_i | X_i = x)$.\nThe privacy mechanism is to be said non interactive if each $Z_i$ is obtained only conditionnaly on $X_i$ (and not on the others). This represents the fact that the privacy mechanism is memory less. If not, the mechnism is said to be interactive.\nIn the following, we will work only with non-interactive privacy mechanism but in the conlusion we will claim that newer studies showed that it is not enough for some larger problems.\n$Z_i$ is said to be α-local-differentially private for the original data $X_i$ if $$sup(\\frac{Q(Z | X_i = x)}{Q(Z | X_i = x\u0026rsquo;)} | x, x\u0026rsquo; ∈ X) ≤ exp(α)$$.\nAn intuitive way of understanding this definition is to see that the smaller α is (the more private it is), the more difficult it is to distinguish the distribution of Z conditional on two different X data.\nTheoretical results The case of multinomial estimation In this section, we return back to the problem of the private survey. For the statistician view, estimating a survey is estimating the parameter θ from the Bernouilli distribution $B(θ)$. This problem is a special case of multinomial estimation, where θ is now a multidimensional parameter that is amenable to simplex probability. $∆d := (θ ∈ ℝ+ |∑θ_j = 1)$.\nTheorem : Given α-local-differentially private $Z_i$, there exists some arbitrary constants $C_1$, $C_2$ such that for all $\\alpha\\in [0,1]$: $$C_1 min(1, \\frac{1}{\\sqrt{n\\alpha^2}}, \\frac{d}{n\\alpha^2}) ≤ E[|θ_{hat} - θ|^2] ≤ C_2 min(1, \\frac{d}{n\\alpha^2})$$ and $$C_1 min(1,\\frac{1}{\\sqrt{n\\alpha^2}}) ≤ E[||θ_{hat} - θ||_1] ≤ C_2 min(1,\\frac{d}{\\sqrt{n\\alpha^2}})$$.\nRecall from standard statistics: For non private independant $Z_i$ with finite variance, there exists some arbitrary constants $C_3$ such that: $$E[|θ_{hat} - θ|^2] ≤ \\frac{C_3}{n}$$\nIn others term, providing α-local-differentially privacy causes a reduction in the effective sample size of a factor $\\frac{\\alpha^2}{d}$ for best situations. It thus means that the asymptotically rate of convergences remains unchanged which is a really good news !\nPractical strategies The paper deals with one of the 2 standard methods to implement such a strategy that obtains the minimax rates:\nRandomized responses Laplace Noise (beyond paper) Randomized responses The intuition of this section is the following : to not allow the statistician to retrieve your personnal data in case of Bernouilli distribution, you toss a coin. If it is heads, you say to him your reel answer, if it is tails, you say the opposite. In his point of view, as he doesn\u0026rsquo;t know what was the result of the coin, he can\u0026rsquo;t distinguish if you tell the true or not but in a large scale, he knows that he will have half correct answer, half lies so that he can retrieve information.\nFor the multinomial estimation now, you will generalize this procedure to the multidimensionnal setting. For each coordinate, you will tell to the statistician the reel answer with a certain probability and lies otherwise. More precisely, its leads to :\n$$[Z]_j = x_j \\text{ with probability } \\frac{e^\\frac{\\alpha}{2}} {1 + e^\\frac{\\alpha}{2}}$$ $$[Z]_j = 1 - x_j \\text{ with probability } \\frac{1}{1 + e^\\frac{\\alpha}{2}}$$\nSuch a mechanism achieves α-local-differentially privacy because one can show that :\n$$\\frac{Q(Z = z | x)}{Q(Z = z | x\u0026rsquo;)} = e^\\frac{\\alpha}{2}(||z - x||_1 - ||z - x\u0026rsquo;||_1) \\in [e^{-\\alpha}, e^\\alpha]$$ which is the criteria given above.\nWith the notation as $1_d=[1, 1, 1, \u0026hellip;, 1]$ corresponds to a d-vector with each coordinate equals 1, we can also show that :\n$$E[Z | x] = \\frac{e^\\frac{\\alpha}{2} - 1}{e^\\frac{\\alpha}{2} + 1} * x + \\frac{1}{1 + e^\\frac{\\alpha}{2}}1_d$$\nThis leads to the natural moment-estimator :\n$$θ_{hat} = \\frac{1}{n} ∑_{i=1}^{n} \\frac{Z_i - 1_d}{1 + e^\\frac{\\alpha}{2}} * \\frac{e^\\frac{\\alpha}{2} + 1}{e^\\frac{\\alpha}{2} - 1}$$\nOne can also show that it verifies :\n$$E[ ||θ_{hat}- θ||_2] ≤ \\frac{d}{n} * \\frac{(e^\\frac{\\alpha}{2} + 1)^2}{(e^\\frac{\\alpha}{2} - 1)^2} \u0026lt; \\frac{C_3}{nα^2}$$ which is the announced result.\nLaplace Noise (beyond paper) Instead of saying the truth with some probability, one may think of adding noise to the answer so that the statistician can\u0026rsquo;t retrieve his real answer. This is exactly the mechanism we propose to dive in and which is not covered in the paper.\nDefinition: A noise is said to be a Laplace noise with parameters (μ, b) if it verifies:\n$$f(x|μ, b) = \\frac{1}{2b} * exp(\\frac{-|x - μ|}{b})$$\nA visualisation for differents parameters is given below. We can see that Laplace distribution is a shaper verson of the gaussian distribution : The trick is to use such a noise. Let assume $X_i \\in [-M,M]$ and construct the private mechanism as follow:\n$$Z_i = X_i + \\sigma W_i$$ where $W_i$ is drawn from a Laplace noise (0,1).\nOne can show that :\n$$\\frac{Q(Z = z | x)}{Q(Z = z | x\u0026rsquo;)} \\leq e^{\\frac{1}{\\sigma} * |x - x\u0026rsquo;|} \\leq e^{\\frac{2M}{\\sigma}}$$\nThus, with the choice of $\\sigma = \\frac{2M}{\\alpha}$, it verifies α-local-differentially privacy. The proposed estimator is the following :\n$$\\hat{Z} = \\bar{X} + \\frac{2M}{\\alpha} \\bar{W}$$\nOne can show that it is an unbiaised estimator that achieves the optimal rates:\n$$E[\\hat{Z}] = E[X]$$\n$$V[\\hat{Z}] = \\frac{V(X)}{n} + \\frac{4M^2}{n\\alpha^2} V[\\bar{W}] = \\frac{V(X)}{n} + \\frac{8M^2}{n\\alpha^2}$$ $$E[ |\\hat{Z}- X|^2] \\leq \\frac{C_3}{n\\alpha^2}.$$\nThis is exactly the optimal rates, quite outstanding !\nThe case of density estimation One accurate question that can raise is : what about others distribution ? Is privacy more costly in general cases ? What is the trade-off ?\nTo answer this question, let\u0026rsquo;s precise the problem.\nWe want to estimate in a non-parametric way a 1D-density function f belonging to one of theses classes :\n-Hölder Class (β, L): $\\text{For all }x, y \\in \\mathbb{R} \\text{ and } m \\leq \\beta, \\quad \\left| f^{(m)}(x) - f^{(m)}(y) \\right| \\leq L \\left| x - y \\right|^{\\beta - m}$\n-Sobolev Class: $F_{\\beta}[C] := \\left( f \\in L^2([0, 1]) , \\middle| , f = \\sum_{j=1}^{\\infty} \\theta_j \\phi_j \\text{ such that } \\sum_{j=1}^{\\infty} j^{2\\beta} \\phi_j^2 \\leq C^2 \\right)$\nIn a intuitition way, those two classes express that f is smooth enough to admits Lipschitz constant to its derivative so that it doesn\u0026rsquo;t \u0026ldquo;vary\u0026rdquo; locally too much.\nTheorem Without privacy One can show that without privacy, the minimax rate achievable for estimating a Hölder Class function is:\n$$\\text{MSE}(\\hat{f} - f) \\leq C_1 \\cdot n^{-\\frac{2\\beta}{1+2\\beta}}$$ with the estimator\n$$\\hat{f}(x) = \\frac{1}{n} \\sum_{i=1}^{n} \\frac{1}{h} K\\left(\\frac{x - X_i}{h}\\right) \\text{with } h = C_2 \\cdot n^{-\\frac{1}{2\\beta+1}}$$\nIn the case of d-multidimensionnal density f, the optimal rate is :\n$$\\text{MSE}(\\hat{f} - f) \\leq C_4 \\cdot n^{-\\frac{2\\beta}{d+ 2\\beta}}$$ with the estimator\n$$\\hat{f}(x) = \\frac{1}{n} \\sum_{i=1}^{n} \\frac{1}{h^d} K^d\\left(\\frac{x-X_i}{h}\\right) \\quad \\text{with} \\quad h = C_5 \\cdot n^{-\\frac{1}{2\\beta + d}}$$\nThis illustrates once again the curse of dimensionnality.\nWith privacy Let assume that f bellongs to one of the two classes with β as smoothness parameter.\nThen, the optimal α-local-differentially private optimal rate is :\n$$\\text{MSE}(\\hat{f} - f) \\leq C_1 \\cdot (n\\alpha^2)^{-\\frac{2\\beta}{2\\beta+2}}.$$\nOne may observe two pessimistic news:\n-The rate is affected by a factor of $\\alpha^2$ as for the multinomial estimation\n-More damageable: the rate is slower in term of n unlike the previous problem which make privacy in this case more costly.\nPractical strategies Eventhough this rate is pessimistic and proves that privacy comes at a cost, it remains to illustrates how can we achieves this best but not great rate. For this end, once again, two strategies are possible.\nRandomized responses Laplace Noise (beyond paper) Randomized responses This is the strategy illustrated in the paper and consists of sampling for each coordinate according the realisation of a Bernouilli variable with the correct probability as function of α. As it is not the most comprehensive and straightforward method, we prefer to dive in depth into the second one; uncovered in the paper.\nLaplace Noise (beyond paper) Let assume that $X_i \\in [0,M]$ almost surely. We note $G_j = [\\frac{j-1}{K},\\quad \\frac{j}{K}]$ the bin of length $\\frac{1}{K}$.\nWe consider the histogramm estimator: $$\\hat{f}(x) = \\frac{K}{n} \\sum_{j=1}^{K} \\sum_{i=1}^{n} 1_{X_i \\in G_j} \\cdot 1_{x \\in G_j}.$$\nWe now construct the private mechanism as follow:\n$$Z_i = \\left[1_{X_i \\in G_1} + \\frac{2}{\\alpha} W_1, \\ldots, 1_{X_i \\in G_K} + \\frac{2}{\\alpha} W_K\\right]$$\nIn an intuitive way, we add a Laplace noise realisation for each bin.\nThis guarantees α-local-differentially privacy as : $$\\frac{Q(Z = z | x)}{Q(Z = z | x\u0026rsquo;)} \\leq \\exp\\left(\\frac{\\alpha}{2} \\sum_{j=1}^{K} |1_{x \\in G_j} - 1_{x\u0026rsquo; \\in G_j}| \\right) \\leq \\exp\\left(\\frac{\\alpha}{2} \\cdot 2\\right).$$\nThis leads to the α-local-differentially private estimator :\n$$f_{\\text{private_estimate}} = \\hat{f} + \\frac{2K}{n\\alpha} \\sum_{j=1}^{K} W_j$$\nThe biais is the same as the unprivate case as :\n$$E[f_{\\text{private_estimate}}] = E[\\hat{f}] + 0 .$$\nOne may prove that if f bellongs to the β-Hölder Class:\n$$Biais(f_{\\text{private_estimate}}, f) \\leq C_1 * K^{-\\beta}$$\nMeanwhile, $$V[f_{\\text{private_estimate}}] \\leq \\frac{C_2}{n} + \\frac{4K^2}{\\alpha^2} \\frac{V[W]}{n}$$, such that in total :\n$$\\text{MSE}(f_{\\text{private_estimate}} - f) \\leq C_1 K^{-2\\beta} + \\frac{C_2}{n} + \\frac{C_3 K^2}{n\\alpha^2}.$$ Minimizing over K (hyperparameters) leads to : $K = C_4 \\cdot (n\\alpha^2)^{-\\frac{1}{2\\beta+2}}$ and thus to:\n$$\\text{MSE}(f_{\\text{private_estimate}} - f) \\leq C_5 \\cdot (n\\alpha^2)^{-\\frac{2\\beta}{2\\beta + 2}}$$, which is the expected bound.\nExperiment: Illustration of the Minimax privacy rate Overview The aim of this section is to provide illustrations of the theoretical results set out above. Emphasis is placed on convergence results, with empirical confirmation of the latter.\nFor the sake of reproducibility and transparency, the source code can be found in the notebook at this: Github link.\nMethodology Data Preparation: Rather than working with real datasets, we decide to work with simulated data, as this allows us to maintain control over all aspects. More precisely, we give ourselves $n=1000$ samples of the normal distribution $N(100,1)$ on which we add a Laplace noise $L(0,\\alpha).$\nAs for the different alpha values, we iterate through them: $[0.2, 0.3, 0.5, 0.7]$\nPrivacy Metric Calculation: We will look at the use case of estimating the mean of a distribution.\nEvaluation: The results will be compared in terms of Mean Square Error (MSE).\nResults In terms of the observed distribution (private because subject to Laplace noise) relative to the true data, we obtain the following figure:\nAs expected, the greater the desired privacy (low $\\alpha$), the more spread out the distribution of observed data.\nWhen it comes to estimating the true average from private data, we obtain the following figure:\nThis figure illustrates two major points:\n-The first is that whatever the level of privacy, we have an unbiased estimator of the mean. It\u0026rsquo;s a beautiful property, empirically verified !\n-The second is that, unfortunately, the greater the privacy (low alpha), the greater the variance of this estimator.\nWe recall our main theorem demonstrated above Previous theorem :\nTheorem : Given α-local-differentially private $Z_i$, there exists some arbitrary constants $C_1$, $C_2$ such that for all $\\alpha\\in [0,1]$: $$C_1 min(1, \\frac{1}{\\sqrt{n\\alpha^2}}, \\frac{d}{n\\alpha^2}) ≤ E[|θ_{hat} - θ|^2] ≤ C_2 min(1, \\frac{d}{n\\alpha^2})$$\nWe now want to compare the theoretical optimal rate with empirical results. To do this, we distinguish two situations:\n-The first is with fixed alpha, and determines the MSE as a function of the number of samples n. This leads to these empirical results:\nThe dotted line represents the regime of the theoretical bound of the form $n \\rightarrow \\frac{C1}{n}$ . This is the shape of the empirical curves!\n-The second has a fixed n and determines the MSE as a function of alpha. This leads to these empirical results:\nThe dotted line represents the regime of the theoretical bound of the form $\\alpha \\rightarrow \\frac{C1}{\\alpha^2}$ . This is once again the shape of the empirical curves quite surprisingly!\nConclusion From a problem rooted in an ethical dilemma (privacy versus completeness and transparency), we have looked at the cost of guaranteeing one at the expense of the other, to better sketch out desirable situations.\nThis has enabled us to develop theoretical results in terms of minimax rates. There is indeed a trade-off between these criteria, which is even more costly in the case of non-parametric density estimation.\nFinally, we have compared these theoretical limits with empirical results, which confirm the conformity of the statements.\nThe aim of all this work is to disseminate this important yet under-exploited notion: privacy. To this end, we invite the reader to take the following quiz to ensure his or her understanding.\nQuizz To test yourself abour privacy:\nWhat is privacy?\nAvoid asking questions that can raise private information A mechanism that prevents other agent to retrieve personnal information in your answer An ethical-washing trend Which situation is α-local-differentially privacy?\nsup {Q(Z | Xi = x)/Q(Z | Xi = x')} | x, x' ∈ X} \u003e= exp(α) You tell the truth half the time, you lie otherwise. Z_i = X_i + (2M/α) W_i with W_i drawn from a Laplace Noise(0,1) What is the privacy cost in term of optimal rate ?\nMultinomial estimation: A factor α^2/d Density estimation: from n^(-2β/2β+2) (without privacy) to (nα^2)^(-2β/(2β+2)) We loose nothing, that's the surprising finding of the paper Submit Annexes References Warner SL. Randomized response: a survey technique for eliminating evasive answer bias. J Am Stat Assoc. 1965 Mar;60(309):63-6. PMID: 12261830. John C. Duchi, Michael I. Jordan, and Martin Wainwright. Local Privacy and Minimax Bounds: Sharp Rates for Probability Estimation. Advances in Neural Information Processing Systems (2013) Dwork, C., \u0026amp; Roth, A. (2014). The algorithmic foundations of differential privacy. Foundations and Trends® in Theoretical Computer Science, 9(3-4), 211-407. Narayanan, A., \u0026amp; Shmatikov, V. (2008). Robust de-anonymization of large sparse datasets. In Security and Privacy, 2008. SP 2008. IEEE Symposium on (pp. 111-125). IEEE. ",
      "content_html": "\u003ch1 style=\"font-size: 36px;\"\u003eEstimating Privacy in Data Science: A Comprehensive Guide\u003c/h1\u003e\n\u003ch1 style=\"font-size: 24px;\"\u003eAuthor: Antoine Klein \u003ca href=\"https://github.com/AntoineTSP\"\u003eGithub Link\u003c/a\u003e\u003c/h1\u003e\n\u003ch1 id=\"table-of-contents\"\u003eTable of Contents\u003c/h1\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"#section-0\"\u003eIncentives\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#section-1\"\u003eIntroduction\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#section-2\"\u003eDefinition\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#section-3\"\u003eTheory\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#section-4\"\u003eThe case of multinomial estimation\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#section-5\"\u003eThe case of density estimation\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#section-6\"\u003eExperiment\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#section-7\"\u003eConclusion\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#section-8\"\u003eQuizz\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"section-0\"\u003eWhy do we care about privacy ?\u003c/h2\u003e\n\u003cp\u003eImagine, you\u0026rsquo;re quietly at home when the doorbell rings. You open the door and a government official appears: population census. Even though he shows you his official badge and you\u0026rsquo;d like to help him in the public interest, you find it hard to answer his questions as you go along. Indeed, the first questions about the date of your move are easy and public. On the other hand, when he asks about the number of children, marital status or your salary and what you do with it, you \u003cem\u003estruggle\u003c/em\u003e. Not because you don\u0026rsquo;t know the answer, but because you\u0026rsquo;re faced with an \u003cstrong\u003eethical dilemma\u003c/strong\u003e: transparency towards the state versus protection of personal data.\u003cbr\u003e\n$$\\text{In short, transparency goes against your privacy. }$$\u003c/p\u003e\n\u003cp\u003eThis stress has major consequences: as you doubt what could happen to you with this data, but you still want to answer it, you \u003cstrong\u003eunderestimate\u003c/strong\u003e your answers. On a wider scale, this leads to a \u003cstrong\u003esuffrage bias\u003c/strong\u003e and therefore a lack of knowledge of the real situation of your population. Warner [1], the first to tackle this problem from a statistical angle talks of an evasive bias and says:\u003cbr\u003e\n\u003cstrong\u003e\u0026ldquo;for reasons of modesty, fear of being thought bigoted, or merely a reluctance to confide secrets to strangers, respondents to surveys might prefer to be able to answer certain questions non-truthfully, or at least without the interviewer knowing their true response\u0026rdquo;\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eThis situation presented a trusted agent, in that he wasn\u0026rsquo;t trying to harm you directly. Now imagine that you agree to give him your personal data, but that on the way home, this agent of the state is mugged and someone steals his documents. Not only is this an attack on his person, it\u0026rsquo;s also an attack on yours: as the guarantor of your data, it\u0026rsquo;s now at the mercy of the attacker. The problem here is \u003cstrong\u003enot to have protected yourself against a malicious agent\u003c/strong\u003e.\u003c/p\u003e\n\u003cp\u003eAdmittedly, these situations are rare, but with the densification of data, their analogies are omnipresent: cookies on the Internet, cyber-attacks, datacenter crashes\u0026hellip;One area for improvement is quite simply to better \u003cstrong\u003ecertify usage\u003c/strong\u003e by means of cyber protection labels and leads to such a norm to achieve trust:\n\u003cimg\n  src=\"/images/Antoine_Klein/Umbrella.png\"\n  alt=\"Data Privacy2\"\n  loading=\"lazy\"\n  decoding=\"async\"\n  class=\"full-width\"\n/\u003e\n\n\u003c/p\u003e\n\u003cp\u003eIn this blog, we propose to tackle this problem from a completely different angle: \u003cstrong\u003ehow to both enable the agent to take global measures and prevent it and any subsequent malicious agents from being able to re-identify my personal data\u003c/strong\u003e. We\u0026rsquo;ll also use minimax bounds to answer the question: \u003cstrong\u003efor a given privacy criterion, what\u0026rsquo;s the loss in terms of estimation?\u003c/strong\u003e (fundamental trade-offs between privacy and convergence rate)\u003c/p\u003e\n\u003ch2 id=\"section-1\"\u003eScientific introduction\u003c/h2\u003e\n\u003cp\u003eOur blog will follow the same plan as the article that inspired it (John C. Duchi [2]),i.e. to show that \u003cstrong\u003eresponse randomization achieves optimal convergence\u003c/strong\u003e in the case of multinomial estimation, and then that this process can be generalized to any \u003cem\u003enonparametric distribution estimation\u003c/em\u003e. To this end, we will introduce the notion of \u003cstrong\u003elocal differential privacy\u003c/strong\u003e as well as the \u003cstrong\u003eminimax theory\u003c/strong\u003e for obtaining optimal limits. All this will shed light on the \u003cstrong\u003etrade-off between privacy and estimation rates\u003c/strong\u003e. We will also explain algorithms to implement these optimal strategies. Finally, we will propose some experimental results.\u003c/p\u003e\n\u003ch2 id=\"section-2\"\u003eSome key definitions\u003c/h2\u003e\n\u003cp\u003eLet assume that you want to make private $X_1 , \u0026hellip; , X_n \\in X$ random variable and, as the statistician, you only observe $Z_1, . . . , Z_n ∈ Z$. The paper assumes that there exist a \u003cstrong\u003emarkov kernel\u003c/strong\u003e that links the true ramdom variables and the observed ones as follow: $Q_i(Z_i | X_i = x)$.\u003c/p\u003e\n\u003cp\u003eThe privacy mechanism is to be said \u003cstrong\u003enon interactive\u003c/strong\u003e if each $Z_i$ is obtained only conditionnaly on $X_i$ (and not on the others). This represents the fact that the privacy mechanism is \u003cstrong\u003ememory less\u003c/strong\u003e. If not, the mechnism is said to be interactive.\u003c/p\u003e\n\u003cp\u003eIn the following, we will work only with non-interactive privacy mechanism but in the conlusion we will claim that newer studies showed that it is not enough for some larger problems.\u003c/p\u003e\n\u003cp\u003e$Z_i$ is said to be \u003cstrong\u003eα-local-differentially private\u003c/strong\u003e for the original data $X_i$ if $$sup(\\frac{Q(Z | X_i = x)}{Q(Z | X_i = x\u0026rsquo;)} | x, x\u0026rsquo; ∈ X) ≤ exp(α)$$.\u003c/p\u003e\n\u003cp\u003eAn intuitive way of understanding this definition is to see that the smaller α is (the more private it is), the more \u003cstrong\u003edifficult it is to distinguish\u003c/strong\u003e the distribution of Z conditional on two different X data.\u003c/p\u003e\n\u003ch2 id=\"section-3\"\u003eTheoretical results\u003c/h2\u003e\n\u003ch3 id=\"section-4\"\u003eThe case of multinomial estimation\u003c/h3\u003e\n\u003cp\u003eIn this section, we return back to the problem of the private survey. For the statistician view, estimating a survey is estimating the parameter θ from the Bernouilli distribution $B(θ)$.\nThis problem is a special case of multinomial estimation, where \u003ccode\u003eθ\u003c/code\u003e is now a multidimensional parameter that is amenable to simplex probability. $∆\u003cem\u003ed := (θ ∈ ℝ\u003c/em\u003e+ |∑θ_j = 1)$.\u003c/p\u003e\n\u003cp\u003e\u003ca name=\"Recall\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eTheorem :\u003c/strong\u003e Given α-local-differentially private $Z_i$, there exists some arbitrary constants $C_1$, $C_2$ such that for all $\\alpha\\in [0,1]$:\n$$C_1 min(1, \\frac{1}{\\sqrt{n\\alpha^2}}, \\frac{d}{n\\alpha^2}) ≤ E[|θ_{hat} - θ|^2] ≤ C_2 min(1, \\frac{d}{n\\alpha^2})$$ and\n$$C_1 min(1,\\frac{1}{\\sqrt{n\\alpha^2}}) ≤ E[||θ_{hat} - θ||_1] ≤ C_2 min(1,\\frac{d}{\\sqrt{n\\alpha^2}})$$.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eRecall from standard statistics:\u003c/strong\u003e For non private independant $Z_i$ with finite variance, there exists some arbitrary constants $C_3$ such that:\n$$E[|θ_{hat} - θ|^2] ≤ \\frac{C_3}{n}$$\u003c/p\u003e\n\u003cp\u003eIn others term, providing α-local-differentially privacy \u003cstrong\u003ecauses a reduction\u003c/strong\u003e in the effective sample size of a factor $\\frac{\\alpha^2}{d}$ for best situations. It thus means that the \u003cstrong\u003easymptotically rate of convergences remains unchanged\u003c/strong\u003e which is a really good news !\u003c/p\u003e\n\u003ch4 id=\"practical-strategies\"\u003ePractical strategies\u003c/h4\u003e\n\u003cp\u003eThe paper deals with one of the 2 standard methods to implement such a strategy that obtains the minimax rates:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"#section-10\"\u003eRandomized responses\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#section-11\"\u003eLaplace Noise (beyond paper)\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch5 id=\"section-10\"\u003eRandomized responses\u003c/h5\u003e\n\u003cp\u003eThe \u003cem\u003eintuition\u003c/em\u003e of this section is the following : \u003cstrong\u003eto not allow the statistician to retrieve your personnal data\u003c/strong\u003e in case of Bernouilli distribution, you toss a coin. If it is heads, you say to him your reel answer, if it is tails, you say the opposite. In his point of view, as he doesn\u0026rsquo;t know what was the result of the coin, \u003cstrong\u003ehe can\u0026rsquo;t distinguish\u003c/strong\u003e if you tell the true or not but in a large scale, he knows that he will have half correct answer, half lies so that he can retrieve information.\u003c/p\u003e\n\u003cp\u003eFor the multinomial estimation now, you will generalize this procedure to the multidimensionnal setting. For each coordinate, you will tell to the statistician the reel answer with a certain probability and lies otherwise. More precisely, its leads to :\u003c/p\u003e\n\u003cp\u003e$$[Z]_j = x_j \\text{ with probability } \\frac{e^\\frac{\\alpha}{2}} {1 + e^\\frac{\\alpha}{2}}$$\n$$[Z]_j = 1 - x_j \\text{ with probability } \\frac{1}{1 + e^\\frac{\\alpha}{2}}$$\u003c/p\u003e\n\u003cp\u003eSuch a mechanism achieves \u003cem\u003eα-local-differentially privacy\u003c/em\u003e because one can show that :\u003c/p\u003e\n\u003cp\u003e$$\\frac{Q(Z = z | x)}{Q(Z = z | x\u0026rsquo;)} = e^\\frac{\\alpha}{2}(||z - x||_1 - ||z - x\u0026rsquo;||_1) \\in [e^{-\\alpha}, e^\\alpha]$$ which is the criteria given above.\u003c/p\u003e\n\u003cp\u003eWith the notation as $1_d=[1, 1, 1, \u0026hellip;, 1]$ corresponds to a d-vector with each coordinate equals 1, we can also show that :\u003c/p\u003e\n\u003cp\u003e$$E[Z | x] = \\frac{e^\\frac{\\alpha}{2} - 1}{e^\\frac{\\alpha}{2} + 1} * x + \\frac{1}{1 + e^\\frac{\\alpha}{2}}1_d$$\u003c/p\u003e\n\u003cp\u003eThis leads to the natural moment-estimator :\u003c/p\u003e\n\u003cp\u003e$$θ_{hat} = \\frac{1}{n} ∑_{i=1}^{n} \\frac{Z_i - 1_d}{1 + e^\\frac{\\alpha}{2}} * \\frac{e^\\frac{\\alpha}{2} + 1}{e^\\frac{\\alpha}{2} - 1}$$\u003c/p\u003e\n\u003cp\u003eOne can also show that it verifies :\u003c/p\u003e\n\u003cp\u003e$$E[ ||θ_{hat}- θ||_2] ≤  \\frac{d}{n} * \\frac{(e^\\frac{\\alpha}{2} + 1)^2}{(e^\\frac{\\alpha}{2} - 1)^2} \u0026lt; \\frac{C_3}{nα^2}$$ which is the announced result.\u003c/p\u003e\n\u003ch5 id=\"section-11\"\u003eLaplace Noise (beyond paper)\u003c/h5\u003e\n\u003cp\u003eInstead of saying the truth with some probability, one may think of \u003cstrong\u003eadding noise\u003c/strong\u003e to the answer so that the statistician can\u0026rsquo;t retrieve his real answer. This is exactly the mechanism we propose to dive in and which is \u003cstrong\u003enot covered in the paper\u003c/strong\u003e.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eDefinition:\u003c/strong\u003e A noise is said to be a Laplace noise with parameters (μ, b) if it verifies:\u003cbr\u003e\n$$f(x|μ, b) = \\frac{1}{2b} * exp(\\frac{-|x - μ|}{b})$$\u003c/p\u003e\n\u003cp\u003eA visualisation for differents parameters is given below. We can see that Laplace distribution is a \u003cstrong\u003eshaper verson of the gaussian distribution\u003c/strong\u003e :\n\u003cimg\n  src=\"/images/Antoine_Klein/Laplace.png\"\n  alt=\"Laplace\"\n  loading=\"lazy\"\n  decoding=\"async\"\n  class=\"full-width\"\n/\u003e\n\n\u003c/p\u003e\n\u003cp\u003eThe trick is to use such a noise. Let assume $X_i \\in [-M,M]$ and construct the private mechanism as follow:\u003cbr\u003e\n$$Z_i = X_i + \\sigma W_i$$ where $W_i$ is drawn from a Laplace noise (0,1).\u003c/p\u003e\n\u003cp\u003eOne can show that :\u003c/p\u003e\n\u003cp\u003e$$\\frac{Q(Z = z | x)}{Q(Z = z | x\u0026rsquo;)} \\leq e^{\\frac{1}{\\sigma} * |x - x\u0026rsquo;|} \\leq e^{\\frac{2M}{\\sigma}}$$\u003c/p\u003e\n\u003cp\u003eThus, with the choice of $\\sigma = \\frac{2M}{\\alpha}$, \u003cstrong\u003eit verifies α-local-differentially privacy\u003c/strong\u003e. The proposed estimator is the following :\u003cbr\u003e\n$$\\hat{Z} = \\bar{X} + \\frac{2M}{\\alpha} \\bar{W}$$\u003c/p\u003e\n\u003cp\u003eOne can show that it is an unbiaised estimator that achieves the optimal rates:\u003cbr\u003e\n$$E[\\hat{Z}] = E[X]$$\u003cbr\u003e\n$$V[\\hat{Z}] = \\frac{V(X)}{n} + \\frac{4M^2}{n\\alpha^2} V[\\bar{W}] = \\frac{V(X)}{n} + \\frac{8M^2}{n\\alpha^2}$$\n$$E[ |\\hat{Z}- X|^2] \\leq \\frac{C_3}{n\\alpha^2}.$$\u003c/p\u003e\n\u003cp\u003eThis is \u003cstrong\u003eexactly the optimal rates\u003c/strong\u003e, quite outstanding !\u003c/p\u003e\n\u003ch3 id=\"section-5\"\u003eThe case of density estimation\u003c/h3\u003e\n\u003cp\u003eOne accurate question that can raise is : \u003cstrong\u003ewhat about others distribution ?\u003c/strong\u003e Is privacy more costly in general cases ? What is the trade-off ?\u003c/p\u003e\n\u003cp\u003eTo answer this question, let\u0026rsquo;s precise the problem.\u003c/p\u003e\n\u003cp\u003eWe want to estimate in a non-parametric way a 1D-density function \u003ccode\u003ef\u003c/code\u003e belonging to one of theses classes :\u003cbr\u003e\n-\u003cstrong\u003eHölder Class (β, L):\u003c/strong\u003e $\\text{For all }x, y \\in \\mathbb{R} \\text{ and } m \\leq \\beta, \\quad \\left| f^{(m)}(x) - f^{(m)}(y) \\right| \\leq L \\left| x - y \\right|^{\\beta - m}$\u003cbr\u003e\n-\u003cstrong\u003eSobolev Class:\u003c/strong\u003e $F_{\\beta}[C] := \\left( f \\in L^2([0, 1]) , \\middle| , f = \\sum_{j=1}^{\\infty} \\theta_j \\phi_j \\text{ such that } \\sum_{j=1}^{\\infty} j^{2\\beta} \\phi_j^2 \\leq C^2 \\right)$\u003c/p\u003e\n\u003cp\u003eIn a intuitition way, those two classes express that \u003ccode\u003ef\u003c/code\u003e is \u003cstrong\u003esmooth enough\u003c/strong\u003e to admits Lipschitz constant to its derivative so that it doesn\u0026rsquo;t \u0026ldquo;vary\u0026rdquo; locally too much.\u003c/p\u003e\n\u003ch4 id=\"theorem\"\u003eTheorem\u003c/h4\u003e\n\u003ch5 id=\"without-privacy\"\u003eWithout privacy\u003c/h5\u003e\n\u003cp\u003eOne can show that without privacy, the minimax rate achievable for estimating a Hölder Class function is:\u003cbr\u003e\n$$\\text{MSE}(\\hat{f} - f) \\leq C_1 \\cdot n^{-\\frac{2\\beta}{1+2\\beta}}$$ with the estimator\u003cbr\u003e\n$$\\hat{f}(x) = \\frac{1}{n} \\sum_{i=1}^{n} \\frac{1}{h} K\\left(\\frac{x - X_i}{h}\\right) \\text{with } h = C_2 \\cdot n^{-\\frac{1}{2\\beta+1}}$$\u003c/p\u003e\n\u003cp\u003eIn the case of d-multidimensionnal density \u003ccode\u003ef\u003c/code\u003e, the optimal rate is :\u003cbr\u003e\n$$\\text{MSE}(\\hat{f} - f) \\leq C_4 \\cdot n^{-\\frac{2\\beta}{d+ 2\\beta}}$$ with the estimator\u003cbr\u003e\n$$\\hat{f}(x) = \\frac{1}{n} \\sum_{i=1}^{n} \\frac{1}{h^d} K^d\\left(\\frac{x-X_i}{h}\\right) \\quad \\text{with} \\quad h = C_5 \\cdot n^{-\\frac{1}{2\\beta + d}}$$\u003c/p\u003e\n\u003cp\u003eThis illustrates once again the \u003cstrong\u003ecurse of dimensionnality\u003c/strong\u003e.\u003c/p\u003e\n\u003ch5 id=\"with-privacy\"\u003eWith privacy\u003c/h5\u003e\n\u003cp\u003eLet assume that \u003ccode\u003ef\u003c/code\u003e bellongs to one of the two classes with  \u003ccode\u003eβ\u003c/code\u003e as smoothness parameter.\u003cbr\u003e\nThen, the optimal α-local-differentially private optimal rate is :\u003cbr\u003e\n$$\\text{MSE}(\\hat{f} - f) \\leq C_1 \\cdot (n\\alpha^2)^{-\\frac{2\\beta}{2\\beta+2}}.$$\u003c/p\u003e\n\u003cp\u003eOne may observe \u003cstrong\u003etwo pessimistic news\u003c/strong\u003e:\u003cbr\u003e\n-The rate is \u003cstrong\u003eaffected by a factor\u003c/strong\u003e of $\\alpha^2$ as for the multinomial estimation\u003cbr\u003e\n-More damageable: the \u003cstrong\u003erate is slower\u003c/strong\u003e in term of \u003ccode\u003en\u003c/code\u003e unlike the previous problem which make privacy in this case \u003cstrong\u003emore costly\u003c/strong\u003e.\u003c/p\u003e\n\u003ch5 id=\"practical-strategies-1\"\u003ePractical strategies\u003c/h5\u003e\n\u003cp\u003eEventhough this rate is pessimistic and proves that \u003cstrong\u003eprivacy comes at a cost\u003c/strong\u003e, it remains to illustrates how can we achieves this best but not great rate.\nFor this end, once again, two strategies are possible.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"#section-12\"\u003eRandomized responses\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#section-13\"\u003eLaplace Noise (beyond paper)\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch5 id=\"section-12\"\u003eRandomized responses\u003c/h5\u003e\n\u003cp\u003eThis is the strategy illustrated in the paper and consists of sampling for each coordinate according the realisation of a Bernouilli variable with the correct probability as function of \u003ccode\u003eα\u003c/code\u003e.\nAs it is not the most comprehensive and straightforward method, \u003cstrong\u003ewe prefer to dive in depth into the second one; uncovered in the paper\u003c/strong\u003e.\u003c/p\u003e\n\u003ch5 id=\"section-13\"\u003eLaplace Noise (beyond paper)\u003c/h5\u003e\n\u003cp\u003eLet assume that $X_i \\in [0,M]$ almost surely. We note $G_j = [\\frac{j-1}{K},\\quad \\frac{j}{K}]$ the bin of length $\\frac{1}{K}$.\u003c/p\u003e\n\u003cp\u003eWe consider the histogramm estimator:\n$$\\hat{f}(x) = \\frac{K}{n} \\sum_{j=1}^{K} \\sum_{i=1}^{n} 1_{X_i \\in G_j} \\cdot 1_{x \\in G_j}.$$\u003c/p\u003e\n\u003cp\u003eWe now construct the private mechanism as follow:\u003cbr\u003e\n$$Z_i = \\left[1_{X_i \\in G_1} + \\frac{2}{\\alpha} W_1, \\ldots, 1_{X_i \\in G_K} + \\frac{2}{\\alpha} W_K\\right]$$\u003c/p\u003e\n\u003cp\u003eIn an intuitive way, we add a Laplace noise realisation for each bin.\u003c/p\u003e\n\u003cp\u003eThis guarantees α-local-differentially privacy as :\n$$\\frac{Q(Z = z | x)}{Q(Z = z | x\u0026rsquo;)} \\leq \\exp\\left(\\frac{\\alpha}{2} \\sum_{j=1}^{K} |1_{x \\in G_j} - 1_{x\u0026rsquo; \\in G_j}| \\right) \\leq \\exp\\left(\\frac{\\alpha}{2} \\cdot 2\\right).$$\u003c/p\u003e\n\u003cp\u003eThis leads to the α-local-differentially private estimator :\u003cbr\u003e\n$$f_{\\text{private_estimate}} = \\hat{f} + \\frac{2K}{n\\alpha} \\sum_{j=1}^{K} W_j$$\u003c/p\u003e\n\u003cp\u003eThe biais is the same as the unprivate case as :\u003cbr\u003e\n$$E[f_{\\text{private_estimate}}] = E[\\hat{f}] + 0 .$$\u003c/p\u003e\n\u003cp\u003eOne may prove that if f bellongs to the β-Hölder Class:\u003cbr\u003e\n$$Biais(f_{\\text{private_estimate}}, f) \\leq C_1 * K^{-\\beta}$$\u003c/p\u003e\n\u003cp\u003eMeanwhile, $$V[f_{\\text{private_estimate}}] \\leq \\frac{C_2}{n} + \\frac{4K^2}{\\alpha^2} \\frac{V[W]}{n}$$, such that in total  :\u003cbr\u003e\n$$\\text{MSE}(f_{\\text{private_estimate}} - f) \\leq C_1 K^{-2\\beta} + \\frac{C_2}{n} + \\frac{C_3 K^2}{n\\alpha^2}.$$\nMinimizing over K (hyperparameters) leads to :  $K = C_4 \\cdot (n\\alpha^2)^{-\\frac{1}{2\\beta+2}}$ and thus to:\u003cbr\u003e\n$$\\text{MSE}(f_{\\text{private_estimate}} - f) \\leq C_5 \\cdot (n\\alpha^2)^{-\\frac{2\\beta}{2\\beta + 2}}$$, which is the expected bound.\u003c/p\u003e\n\u003chr\u003e\n\u003ch2 id=\"section-6\"\u003eExperiment: Illustration of the Minimax privacy rate\u003c/h2\u003e\n\u003ch3 id=\"section-111\"\u003eOverview\u003c/h3\u003e\n\u003cp\u003eThe aim of this section is to \u003cstrong\u003eprovide illustrations of the theoretical results\u003c/strong\u003e set out above. Emphasis is placed on convergence results, with empirical confirmation of the latter.\u003c/p\u003e\n\u003cp\u003eFor the sake of \u003cstrong\u003ereproducibility and transparency\u003c/strong\u003e, the source code can be found in the notebook at this: \u003ca href=\"https://github.com/AntoineTSP/responsible-ai-datascience-ipParis.github.io.git\"\u003eGithub link\u003c/a\u003e.\u003c/p\u003e\n\u003ch3 id=\"methodology\"\u003eMethodology\u003c/h3\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eData Preparation\u003c/strong\u003e: Rather than working with real datasets, we decide to work with simulated data, as this allows us to maintain control over all aspects.\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eMore precisely, we give ourselves $n=1000$ samples of the normal distribution $N(100,1)$ on which we add a Laplace noise $L(0,\\alpha).$\u003cbr\u003e\nAs for the different alpha values, we iterate through them: $[0.2, 0.3, 0.5, 0.7]$\u003c/p\u003e\n\u003col start=\"2\"\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003ePrivacy Metric Calculation\u003c/strong\u003e: We will look at the use case of estimating the mean of a distribution.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eEvaluation\u003c/strong\u003e: The results will be compared in terms of Mean Square Error (MSE).\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3 id=\"results\"\u003eResults\u003c/h3\u003e\n\u003cp\u003eIn terms of the observed distribution (private because subject to Laplace noise) relative to the true data, we obtain the following figure:\u003c/p\u003e\n\u003cp\u003e\u003cimg\n  src=\"/images/Antoine_Klein/Private_distribution.png\"\n  alt=\"Data Privacy2\"\n  loading=\"lazy\"\n  decoding=\"async\"\n  class=\"full-width\"\n/\u003e\n\n\u003c/p\u003e\n\u003cp\u003eAs expected, the greater the desired privacy (low $\\alpha$), \u003cstrong\u003ethe more spread out\u003c/strong\u003e the distribution of observed data.\u003c/p\u003e\n\u003cp\u003eWhen it comes to estimating the true average from private data, we obtain the following figure:\u003c/p\u003e\n\u003cp\u003e\u003cimg\n  src=\"/images/Antoine_Klein/Estimated_mean.png\"\n  alt=\"Data Privacy2\"\n  loading=\"lazy\"\n  decoding=\"async\"\n  class=\"full-width\"\n/\u003e\n\n\u003c/p\u003e\n\u003cp\u003eThis figure illustrates two major points:\u003cbr\u003e\n-The first is that whatever the level of privacy, we have an \u003cstrong\u003eunbiased estimator\u003c/strong\u003e of the mean. It\u0026rsquo;s a beautiful property, empirically verified !\u003cbr\u003e\n-The second is that, unfortunately, the greater the privacy (low alpha), \u003cstrong\u003ethe greater the variance\u003c/strong\u003e of this estimator.\u003c/p\u003e\n\u003cp\u003eWe recall our main theorem demonstrated above \u003ca href=\"#Recall\" style=\"background-color: yellow; padding: 2px 5px; border-radius: 3px;\"\u003ePrevious theorem\u003c/a\u003e :\u003cbr\u003e\n\u003cstrong\u003eTheorem\u003c/strong\u003e : Given α-local-differentially private $Z_i$, there exists some arbitrary constants $C_1$, $C_2$ such that for all $\\alpha\\in [0,1]$:\n$$C_1 min(1, \\frac{1}{\\sqrt{n\\alpha^2}}, \\frac{d}{n\\alpha^2}) ≤ E[|θ_{hat} - θ|^2] ≤ C_2 min(1, \\frac{d}{n\\alpha^2})$$\u003c/p\u003e\n\u003cp\u003eWe now want to \u003cstrong\u003ecompare the theoretical optimal rate with empirical results\u003c/strong\u003e. To do this, we distinguish two situations:\u003cbr\u003e\n-The first is with \u003cstrong\u003efixed alpha\u003c/strong\u003e, and determines the MSE as a function of the number of samples n. This leads to these empirical results:\u003c/p\u003e\n\u003cp\u003e\u003cimg\n  src=\"/images/Antoine_Klein/Minimax_rate_n.png\"\n  alt=\"Data Privacy2\"\n  loading=\"lazy\"\n  decoding=\"async\"\n  class=\"full-width\"\n/\u003e\n\n\u003c/p\u003e\n\u003cp\u003eThe dotted line represents the regime of the theoretical bound of the form $n \\rightarrow \\frac{C1}{n}$ . This is the shape of the empirical curves!\u003c/p\u003e\n\u003cp\u003e-The second has a \u003cstrong\u003efixed n\u003c/strong\u003e and determines the MSE as a function of alpha. This leads to these empirical results:\u003c/p\u003e\n\u003cp\u003e\u003cimg\n  src=\"/images/Antoine_Klein/Minimax_rate_alpha.png\"\n  alt=\"Data Privacy2\"\n  loading=\"lazy\"\n  decoding=\"async\"\n  class=\"full-width\"\n/\u003e\n\n\u003c/p\u003e\n\u003cp\u003eThe dotted line represents the regime of the theoretical bound of the form $\\alpha \\rightarrow \\frac{C1}{\\alpha^2}$ . This is once again the shape of the empirical curves quite surprisingly!\u003c/p\u003e\n\u003ch3 id=\"section-7\"\u003eConclusion\u003c/h3\u003e\n\u003cp\u003eFrom a problem rooted in an \u003cstrong\u003eethical dilemma\u003c/strong\u003e (privacy versus completeness and transparency), we have looked at the \u003cstrong\u003ecost of guaranteeing\u003c/strong\u003e one at the expense of the other, to better sketch out desirable situations.\u003cbr\u003e\nThis has enabled us to develop theoretical results in terms of \u003cstrong\u003eminimax rates\u003c/strong\u003e. There is indeed a \u003cstrong\u003etrade-off\u003c/strong\u003e between these criteria, which is even more costly in the case of non-parametric density estimation.\u003cbr\u003e\nFinally, we have compared these theoretical limits with empirical results, which \u003cstrong\u003econfirm the conformity of the statements\u003c/strong\u003e.\u003cbr\u003e\nThe aim of all this work is to disseminate this important yet under-exploited notion: privacy. To this end, we invite the reader to take the following \u003cstrong\u003equiz\u003c/strong\u003e to ensure his or her understanding.\u003c/p\u003e\n\u003ch1 id=\"section-8\"\u003eQuizz\u003c/h1\u003e\n\u003cp\u003eTo test yourself abour privacy:\u003c/p\u003e\n\u003cform id=\"quiz-form\" class=\"quiz-form\"\u003e\n    \u003cdiv class=\"quiz-question\"\u003e\n        \u003cp\u003eWhat is privacy?\u003c/p\u003e\n        \u003cdiv class=\"quiz-options\"\u003e\n            \u003clabel\u003e\n                \u003cinput type=\"radio\" name=\"question1\" value=\"1\"\u003e\n                Avoid asking questions that can raise private information\n            \u003c/label\u003e\n            \u003clabel\u003e\n                \u003cinput type=\"radio\" name=\"question1\" value=\"2\"\u003e\n                A mechanism that prevents other agent to retrieve personnal information in your answer\n            \u003c/label\u003e\n            \u003clabel\u003e\n                \u003cinput type=\"radio\" name=\"question1\" value=\"3\"\u003e\n                An ethical-washing trend\n            \u003c/label\u003e\n        \u003c/div\u003e\n        \u003cp\u003eWhich situation is α-local-differentially privacy?\u003c/p\u003e\n        \u003cdiv class=\"quiz-options\"\u003e\n            \u003clabel\u003e\n                \u003cinput type=\"radio\" name=\"question2\" value=\"1\"\u003e\n                sup {Q(Z | Xi = x)/Q(Z | Xi = x')} | x, x' ∈ X} \u003e= exp(α)\n            \u003c/label\u003e\n            \u003clabel\u003e\n                \u003cinput type=\"radio\" name=\"question2\" value=\"2\"\u003e\n                You tell the truth half the time, you lie otherwise.\n            \u003c/label\u003e\n            \u003clabel\u003e\n                \u003cinput type=\"radio\" name=\"question2\" value=\"3\"\u003e\n                Z_i = X_i + (2M/α) W_i with W_i drawn from a Laplace Noise(0,1)\n            \u003c/label\u003e\n        \u003c/div\u003e\n        \u003cp\u003eWhat is the privacy cost in term of optimal rate ?\u003c/p\u003e\n        \u003cdiv class=\"quiz-options\"\u003e\n            \u003clabel\u003e\n                \u003cinput type=\"radio\" name=\"question3\" value=\"1\"\u003e\n                Multinomial estimation: A factor α^2/d\n            \u003c/label\u003e\n            \u003clabel\u003e\n                \u003cinput type=\"radio\" name=\"question3\" value=\"2\"\u003e\n                Density estimation: from n^(-2β/2β+2) (without privacy) to (nα^2)^(-2β/(2β+2))\n            \u003c/label\u003e\n            \u003clabel\u003e\n                \u003cinput type=\"radio\" name=\"question3\" value=\"3\"\u003e\n                We loose nothing, that's the surprising finding of the paper\n            \u003c/label\u003e\n        \u003c/div\u003e\n    \u003c/div\u003e\n    \u003c!-- Add more quiz questions as needed --\u003e\n    \u003cbutton type=\"submit\" class=\"quiz-submit\"\u003eSubmit\u003c/button\u003e\n\u003c/form\u003e\n\u003cdiv id=\"quiz-results\" class=\"quiz-results\"\u003e\u003c/div\u003e\n\u003cscript\u003e\n    // Define quiz questions and correct answers\n    const quizQuestions = [\n        {\n            question: \"What is privacy?\",\n            answer: \"2\"\n        },\n        //Add more quiz questions as needed\n        {\n            question: \"Which situation is α-local-differentially privacy?\",\n            answer: \"3\"\n        },\n        //Add more quiz questions as needed\n        {\n            question: \"What is the privacy cost in term of optimal rate ?\",\n            answer: \"1\"\n        }\n    ];\n\n    // Handle form submission\n    document.getElementById('quiz-form').addEventListener('submit', function(event) {\n        event.preventDefault();\n\n        // Calculate quiz score\n        let score = 0;\n        quizQuestions.forEach(question =\u003e {\n            const selectedAnswer = document.querySelector(`input[name=\"question${quizQuestions.indexOf(question) + 1}\"]:checked`);\n            if (selectedAnswer) {\n                if (selectedAnswer.value.toLowerCase() === question.answer) {\n                    score++;\n                    selectedAnswer.parentElement.classList.add('correct');\n                } else {\n                    selectedAnswer.parentElement.classList.add('incorrect');\n                }\n            }\n        });\n\n        // Display quiz results\n        const quizResults = document.getElementById('quiz-results');\n        quizResults.innerHTML = `\u003cp\u003eYou scored ${score} out of ${quizQuestions.length}.\u003c/p\u003e`;\n    });\n\u003c/script\u003e\n\u003chr\u003e\n\u003chr\u003e\n\u003ch2 id=\"annexes\"\u003eAnnexes\u003c/h2\u003e\n\u003ch3 id=\"references\"\u003eReferences\u003c/h3\u003e\n\u003col\u003e\n\u003cli\u003eWarner SL. Randomized response: a survey technique for eliminating evasive answer bias. J Am Stat Assoc. 1965 Mar;60(309):63-6. PMID: 12261830.\u003c/li\u003e\n\u003cli\u003eJohn C. Duchi, Michael I. Jordan, and Martin Wainwright. Local Privacy and Minimax Bounds: Sharp Rates for Probability Estimation. Advances in Neural Information Processing Systems (2013)\u003c/li\u003e\n\u003cli\u003eDwork, C., \u0026amp; Roth, A. (2014). The algorithmic foundations of differential privacy. Foundations and Trends® in Theoretical Computer Science, 9(3-4), 211-407.\u003c/li\u003e\n\u003cli\u003eNarayanan, A., \u0026amp; Shmatikov, V. (2008). Robust de-anonymization of large sparse datasets. In Security and Privacy, 2008. SP 2008. IEEE Symposium on (pp. 111-125). IEEE.\u003c/li\u003e\n\u003c/ol\u003e\n\u003cscript\u003e\nfunction highlight(text) {\n  var inputText = document.getElementById(\"markdown-content\");\n  var innerHTML = inputText.innerHTML;\n  var index = innerHTML.indexOf(text);\n  if (index \u003e= 0) {\n    innerHTML = innerHTML.substring(0,index) + \"\u003cspan class='highlight'\u003e\" + innerHTML.substring(index,index+text.length) + \"\u003c/span\u003e\" + innerHTML.substring(index + text.length);\n    inputText.innerHTML = innerHTML;\n  }\n}\nhighlight(\"Estimating Privacy in Data Science\");\n\n\u003c/script\u003e\n\u003chr\u003e\n\u003cscript\u003e\n    function displayInput() {\n        var inputValue = document.getElementById(\"inputField\").value;\n        document.getElementById(\"output\").innerText = \"You typed: \" + inputValue;\n    }\n\u003c/script\u003e\n\u003cstyle\u003e\n.highlight {\n  background-color: red;\n}\n.highlight-on-hover:hover {\n        background-color: yellow;\n    }\n/* Quiz form styles */\n.quiz-form {\n        max-width: 500px;\n        margin: auto;\n        padding: 20px;\n        border: 1px solid #ccc;\n        border-radius: 5px;\n        background-color: #f9f9f9;\n}\n\n.quiz-question {\n        margin-bottom: 20px;\n}\n\n.quiz-options label {\n        display: block;\n        margin-bottom: 10px;\n}\n\n.quiz-submit {\n        background-color: #4caf50;\n        color: white;\n        padding: 10px 20px;\n        border: none;\n        border-radius: 5px;\n        cursor: pointer;\n}\n\n.quiz-submit:hover {\n        background-color: #45a049;\n}\n\n/* Quiz results styles */\n.quiz-results {\n        margin-top: 20px;\n        font-weight: bold;\n}\n.quiz-options label {\n        display: block;\n        margin-bottom: 10px;\n    }\n.quiz-options label.correct {\n        color: green;\n}\n.quiz-options label.incorrect {\n        color: red;\n}\na[name]:hover {\n        background-color: yellow; /* Change to the same color as normal state to maintain yellow highlight */\n        text-decoration: none; /* Optionally remove underline on hover */\n}\n\u003c/style\u003e\n\u003cstyle TYPE=\"text/css\"\u003e\ncode.has-jax {font: inherit; font-size: 100%; background: inherit; border: inherit;}\n\u003c/style\u003e\n\u003cscript type=\"text/x-mathjax-config\"\u003e\nMathJax.Hub.Config({\n    tex2jax: {\n        inlineMath: [['$','$'], ['\\\\(','\\\\)']],\n        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'] // removed 'code' entry\n    }\n});\nMathJax.Hub.Queue(function() {\n    var all = MathJax.Hub.getAllJax(), i;\n    for(i = 0; i \u003c all.length; i += 1) {\n        all[i].SourceElement().parentNode.className += ' has-jax';\n    }\n});\n\u003c/script\u003e\n\u003cscript type=\"text/javascript\" src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS_HTML-full\"\u003e\u003c/script\u003e\n",
      "url": "http://localhost:1313/posts/statistical_minimax_rates_under_privacy/",
      "date_published": "31016-31-09T122:3131:00+01:00",
      "date_modified": "31016-31-09T122:3131:00+01:00",
      "author": {
        "name": "Students from M2 Data Science IP Paris",
        "url": "http://localhost:1313/"
      }
    },
    
    {
      "id": "aba6ac7516897c4ee7afcdf83296daebaa43622b",
      "title": "Another article",
      "summary": "",
      "content_text": "Authors : John Smith and John Smith\nDo not forget to add the script posted on moodle to enable latex in your blogpost! What a beauty! $y=\\theta_0 + \\theta_1x_1$\n",
      "content_html": "\u003cp\u003e\u003cstrong\u003eAuthors\u003c/strong\u003e : John Smith and John Smith\u003c/p\u003e\n\u003chr\u003e\u003c/hr\u003e\n\u003cstyle\nTYPE=\"text/css\"\u003e\n\u003cp\u003ecode.has-jax {font:\ninherit;\nfont-size:\n100%;\nbackground:\ninherit;\nborder:\ninherit;}\u003c/p\u003e\n\u003cp\u003e\u003c/style\u003e\u003c/p\u003e\n\u003cscript\ntype=\"text/x-mathjax-config\"\u003e\n\nMathJax.Hub.Config({\n\n    tex2jax: {\n\n        inlineMath: [['$','$'], ['\\\\(','\\\\)']],\n\n        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'] // removed 'code' entry\n\n    }\n\n});\n\nMathJax.Hub.Queue(function() {\n\n    var all = MathJax.Hub.getAllJax(), i;\n\n    for(i = 0; i \u003c all.length; i += 1) {\n\n        all[i].SourceElement().parentNode.className += ' has-jax';\n\n    }\n\n});\n\n\u003c/script\u003e\n\u003cscript\ntype=\"text/javascript\"\nsrc=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS_HTML-full\"\u003e\u003c/script\u003e\n\u003cp\u003eDo not forget to add the script posted on moodle to enable latex in your blogpost!\nWhat a beauty! $y=\\theta_0 + \\theta_1x_1$\u003c/p\u003e\n",
      "url": "http://localhost:1313/posts/my-first-blog/",
      "date_published": "8016-08-09T126:88:00+01:00",
      "date_modified": "8016-08-09T126:88:00+01:00",
      "author": {
        "name": "Students from M2 Data Science IP Paris",
        "url": "http://localhost:1313/"
      }
    },
    
    {
      "id": "94409f4b19cf119747df5e05d9507c6fc3ae2286",
      "title": "Title of the article",
      "summary": "",
      "content_text": "Authors : John Smith and John Smith\nStart writing here !\n",
      "content_html": "\u003cp\u003e\u003cstrong\u003eAuthors\u003c/strong\u003e : John Smith and John Smith\u003c/p\u003e\n\u003chr\u003e\u003c/hr\u003e\n\u003cp\u003eStart writing here !\u003c/p\u003e\n",
      "url": "http://localhost:1313/posts/my-second-blog/",
      "date_published": "8016-08-09T126:88:00+01:00",
      "date_modified": "8016-08-09T126:88:00+01:00",
      "author": {
        "name": "Students from M2 Data Science IP Paris",
        "url": "http://localhost:1313/"
      }
    }
    
  ]
}